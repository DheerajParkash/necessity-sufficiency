{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b59e7dbd",
   "metadata": {},
   "source": [
    "The code for ILM is included in this repository, but the original and the setup instructions can be found [here](https://github.com/chrisdonahue/ilm). Before we can train the model, the compound dataset that we've created in the previous notebook needs be preprocessed: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86dca852",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'sh' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!cd ilm\n",
    "!sh create_compound_dataset.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe17188d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['bash', 'ilm/create_compound_dataset.sh'], returncode=1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "subprocess.run([\"bash\", \"ilm/create_compound_dataset.sh\"], shell=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8a3891",
   "metadata": {},
   "source": [
    "Then, we can run the training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55c7fee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "DATASET=compound_dataset\n",
    "TRAIN_DIR=../Models/ILM\n",
    "EXAMPLES_DIR=data/char_masks/${DATASET}\n",
    "python train_ilm.py \\\n",
    "\texperiment_${DATASET} \\\n",
    "\t${TRAIN_DIR} \\\n",
    "\t${EXAMPLES_DIR} \\\n",
    "\t--train_examples_tag train \\\n",
    "\t--eval_examples_tag valid \\\n",
    "\t--train_num_epochs 4 \\\n",
    "\t--eval_max_num_examples 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2c531b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'train_ilm.py', 'experiment_compound_dataset', '../Models/ILM', 'data/char_masks/compound_dataset', '--train_examples_tag', 'train', '--eval_examples_tag', 'valid', '--train_num_epochs', '4', '--eval_max_num_examples', '512'], returncode=2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "DATASET = \"compound_dataset\"\n",
    "TRAIN_DIR = \"../Models/ILM\"\n",
    "EXAMPLES_DIR = f\"data/char_masks/{DATASET}\"\n",
    "\n",
    "cmd = [\n",
    "    \"python\", \"./ilm/train_ilm.py\",\n",
    "    f\"experiment_{DATASET}\",\n",
    "    TRAIN_DIR,\n",
    "    EXAMPLES_DIR,\n",
    "    \"--train_examples_tag\", \"train\",\n",
    "    \"--eval_examples_tag\", \"valid\",\n",
    "    \"--train_num_epochs\", \"4\",\n",
    "    \"--eval_max_num_examples\", \"512\"\n",
    "]\n",
    "\n",
    "subprocess.run(cmd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99790d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STDOUT: Random seed 71650\n",
      "{50257: '<|startofinfill|>', 50258: '<|endofinfill|>', 50259: '<|infill_document|>', 50260: '<|infill_paragraph|>', 50261: '<|infill_sentence|>', 50262: '<|infill_ngram|>', 50263: '<|infill_word|>'}\n",
      "Loading training data\n",
      "\n",
      "STDERR: c:\\Users\\dheer\\OneDrive - Higher Education Commission\\M2 Data Science\\AlgoForSpeecAndTextProcessing\\necessity-sufficiency\\ilm\\train_ilm.py:269: UserWarning: No GPU detected. Training on CPU will be very slow\n",
      "  warnings.warn('No GPU detected. Training on CPU will be very slow')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dheer\\OneDrive - Higher Education Commission\\M2 Data Science\\AlgoForSpeecAndTextProcessing\\necessity-sufficiency\\ilm\\train_ilm.py\", line 738, in <module>\n",
      "    train(args)\n",
      "  File \"c:\\Users\\dheer\\OneDrive - Higher Education Commission\\M2 Data Science\\AlgoForSpeecAndTextProcessing\\necessity-sufficiency\\ilm\\train_ilm.py\", line 322, in train\n",
      "    train_inputs, train_tts, train_num_docs = masked_dataset_to_inputs_and_tts(\n",
      "                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dheer\\OneDrive - Higher Education Commission\\M2 Data Science\\AlgoForSpeecAndTextProcessing\\necessity-sufficiency\\ilm\\train_ilm.py\", line 223, in masked_dataset_to_inputs_and_tts\n",
      "    with open(os.path.join(args.examples_dir, '{}.pkl'.format(examples_tag)), 'rb') as f:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'data/char_masks/compound_dataset\\\\train.pkl'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "cmd = [\n",
    "    \"python\", \"./ilm/train_ilm.py\",\n",
    "    \"experiment_compound_dataset\",\n",
    "    \"../Models/ILM\",\n",
    "    \"data/char_masks/compound_dataset\",\n",
    "    \"--train_examples_tag\", \"train\",\n",
    "    \"--eval_examples_tag\", \"valid\",\n",
    "    \"--train_num_epochs\", \"4\",\n",
    "    \"--eval_max_num_examples\", \"512\"\n",
    "]\n",
    "\n",
    "result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "# Print standard output and error\n",
    "print(\"STDOUT:\", result.stdout)\n",
    "print(\"STDERR:\", result.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf14d18e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "INT_TTRSHP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
